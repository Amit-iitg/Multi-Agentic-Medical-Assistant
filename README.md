# ğŸ©º AI Medical Assistant# ğŸ©º AI Medical Assistant



An AI-powered medical assistant that provides healthcare information through text chat and medical image analysis using multiple specialized AI agents.An AI-powered medical assistant that provides healthcare information through text chat and medical image analysis using multiple specialized AI agents.



## ğŸ“‹ Project Overview## ğŸ“‹ Project Overview



This application allows users to:This application allows users to:

- Ask medical questions via text chat- Ask medical questions via text chat

- Upload medical images for AI analysis- Upload medical images for AI analysis

- Get responses from specialized AI agents (RAG, Web Search, Image Analysis)- Get responses from specialized AI agents (RAG, Web Search, Image Analysis)

- Access medical literature and real-time health information- Access medical literature and real-time health information



## ğŸ“ Project Structure## ğŸ“ Project Structure



``````

Medical-Assistant/Medical-Assistant/

â”œâ”€â”€ backend/                    # Python FastAPI Serverâ”œâ”€â”€ backend/                    # Python FastAPI Server

â”‚   â”œâ”€â”€ main.py                # FastAPI application entryâ”‚   â”œâ”€â”€ main.py                # FastAPI application entry

â”‚   â”œâ”€â”€ requirements.txt       # Python dependenciesâ”‚   â”œâ”€â”€ requirements.txt       # Python dependencies

â”‚   â”‚â”‚   â”‚

â”‚   â””â”€â”€ agents/               # AI Agent Systemâ”‚   â””â”€â”€ agents/               # AI Agent System

â”‚       â”œâ”€â”€ agent_decision.py     # LangGraph orchestrationâ”‚       â”œâ”€â”€ agent_decision.py     # LangGraph orchestration

â”‚       â”œâ”€â”€ guardrails.py         # Content safetyâ”‚       â”œâ”€â”€ guardrails.py         # Content safety

â”‚       â”œâ”€â”€ medical_chat_agent.py # General medical chatâ”‚       â”œâ”€â”€ medical_chat_agent.py # General medical chat

â”‚       â”‚â”‚       â”‚

â”‚       â”œâ”€â”€ rag_agent/            # Document searchâ”‚       â”œâ”€â”€ rag_agent/            # Document search

â”‚       â”‚   â”œâ”€â”€ document_retriever.pyâ”‚       â”‚   â”œâ”€â”€ document_retriever.py

â”‚       â”‚   â”œâ”€â”€ medical_pdfs/     # Medical documentsâ”‚       â”‚   â”œâ”€â”€ medical_pdfs/     # Medical documents

â”‚       â”‚   â””â”€â”€ rag_db/          # ChromaDB storageâ”‚       â”‚   â””â”€â”€ rag_db/          # ChromaDB storage

â”‚       â”‚â”‚       â”‚

â”‚       â”œâ”€â”€ vision_agents/        # Image analysisâ”‚       â”œâ”€â”€ vision_agents/        # Image analysis

â”‚       â”‚   â””â”€â”€ image_analysis_agent.pyâ”‚       â”‚   â””â”€â”€ image_analysis_agent.py

â”‚       â”‚â”‚       â”‚

â”‚       â””â”€â”€ web_search/           # Real-time searchâ”‚       â””â”€â”€ web_search/           # Real-time search

â”‚           â””â”€â”€ web_search_agent.pyâ”‚           â””â”€â”€ web_search_agent.py

â”‚â”‚

â””â”€â”€ frontend/                   # React Applicationâ””â”€â”€ frontend/                   # React Application

    â”œâ”€â”€ package.json           # Node.js dependencies    â”œâ”€â”€ package.json           # Node.js dependencies

    â”œâ”€â”€ src/    â”œâ”€â”€ src/

    â”‚   â”œâ”€â”€ App.js    â”‚   â”œâ”€â”€ App.js

    â”‚   â”œâ”€â”€ components/    â”‚   â”œâ”€â”€ components/

    â”‚   â”‚   â”œâ”€â”€ ChatContainer.js    â”‚   â”‚   â”œâ”€â”€ ChatContainer.js

    â”‚   â”‚   â”œâ”€â”€ ChatMessage.js    â”‚   â”‚   â”œâ”€â”€ ChatMessage.js

    â”‚   â”‚   â””â”€â”€ ChatInput.js    â”‚   â”‚   â””â”€â”€ ChatInput.js

    â”‚   â””â”€â”€ context/    â”‚   â””â”€â”€ context/

    â”‚       â””â”€â”€ ChatContext.js    â”‚       â””â”€â”€ ChatContext.js

    â””â”€â”€ public/    â””â”€â”€ public/

``````



## ğŸ› ï¸ Technology Stack## ğŸ› ï¸ Technology Stack



### Frontend### Frontend

- **React 19.2** - Frontend framework- **React 19.2** - Frontend framework

- **Styled Components** - CSS-in-JS styling- **Styled Components** - CSS-in-JS styling

- **React Markdown** - Markdown rendering- **React Markdown** - Markdown rendering

- **React Dropzone** - File upload- **React Dropzone** - File upload

- **Axios** - HTTP client- **Axios** - HTTP client



### Backend### Backend

- **FastAPI** - Python web framework- **FastAPI** - Python web framework

- **LangGraph** - Multi-agent orchestration- **LangGraph** - Multi-agent orchestration

- **Groq** - AI model inference- **Groq** - AI model inference

- **ChromaDB** - Vector database- **ChromaDB** - Vector database

- **Tavily** - Web search API- **Tavily** - Web search API



## ğŸš€ How to Run## ğŸš€ How to Run



### Prerequisites### Prerequisites

- **Python 3.8+** with pip- **Python 3.8+** with pip

- **Node.js 16+** with npm- **Node.js 16+** with npm



### 1. Clone Repository### 1. Clone Repository

```bash```bash

git clone <repository-url>git clone <repository-url>

cd Medical-Assistantcd Medical-Assistant

``````



### 2. Backend Setup### 2. Backend Setup

```bash```bash

# Create virtual environment# Create virtual environment

python -m venv .venvpython -m venv .venv



# Activate virtual environment# Activate virtual environment

# Windows:# Windows:

.venv\Scripts\activate.venv\Scripts\activate

# macOS/Linux:# macOS/Linux:

source .venv/bin/activatesource .venv/bin/activate



# Install dependencies# Install dependencies

pip install -r requirements.txtpip install -r requirements.txt



# Create .env file in backend folder# Create .env file in backend folder

cd backendcd backend

# Add your API keys to .env:# Add your API keys to .env:

# GROQ_API_KEY=your_groq_api_key# GROQ_API_KEY=your_groq_api_key

# TAVILY_API_KEY=your_tavily_api_key# TAVILY_API_KEY=your_tavily_api_key

# LLM_MODEL_NAME=llama-3.3-70b-versatile# LLM_MODEL_NAME=llama-3.3-70b-versatile



# Start backend# Start backend

uvicorn main:app --reload --host 127.0.0.1 --port 8000uvicorn main:app --reload --host 127.0.0.1 --port 8000

``````



### 3. Frontend Setup### 3. Frontend Setup

```bash```bash

# In new terminal# In new terminal

cd frontendcd frontend



# Install dependencies# Install dependencies

npm installnpm install



# Start frontend# Start frontend

npm startnpm start

``````



### 4. Access Application### 4. Access Application

- **Frontend**: `http://localhost:3000`- **Frontend**: `http://localhost:3000`

- **Backend API**: `http://127.0.0.1:8000`- **Backend API**: `http://127.0.0.1:8000`

- **API Docs**: `http://127.0.0.1:8000/docs`- **API Docs**: `http://127.0.0.1:8000/docs`



### API Keys Required### API Keys Required

- **Groq API**: [https://groq.com](https://groq.com) (for AI models)- **Groq API**: [https://groq.com](https://groq.com) (for AI models)

- **Tavily API**: [https://tavily.com](https://tavily.com) (for web search)- **Tavily API**: [https://tavily.com](https://tavily.com) (for web search)
- **Node.js 16+** with npm
- **Git** for cloning

### 1. Clone the Repository
```bash
git clone <repository-url>
cd Medical-Assistant
```

### 2. Backend Setup

#### Install Python Dependencies
```bash
# Create and activate virtual environment
python -m venv .venv

# Windows
.venv\Scripts\activate

# macOS/Linux
source .venv/bin/activate

# Install packages
pip install -r requirements.txt
```

#### Configure API Keys
Create `backend/.env` file:
```env
GROQ_API_KEY=your_groq_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here
LLM_MODEL_NAME=llama-3.3-70b-versatile
```

**Get API Keys:**
- **Groq API**: [https://groq.com](https://groq.com) (for AI models)
- **Tavily API**: [https://tavily.com](https://tavily.com) (for web search)

### 3. Frontend Setup
```bash
# Navigate to frontend directory
cd frontend

# Install Node.js dependencies
npm install
```

### 4. Start Both Services

#### Terminal 1: Start Backend
```bash
cd backend
uvicorn main:app --reload --host 127.0.0.1 --port 8000
```
âœ… Backend running at: `http://127.0.0.1:8000`

#### Terminal 2: Start Frontend
```bash
cd frontend
npm start
```
âœ… Frontend running at: `http://localhost:3000`

### 5. Access the Application
1. **Open browser**: Navigate to `http://localhost:3000`
2. **Start chatting**: Ask medical questions or upload images
3. **API docs**: Visit `http://127.0.0.1:8000/docs` for backend documentation

---

## ï¿½ Project Structure

### **Frontend Stack**
- **React 19.2**: Modern frontend framework with hooks and functional components
- **Styled Components**: CSS-in-JS for component-based styling
- **React Markdown**: Professional markdown rendering with custom components
- **React Dropzone**: Drag-and-drop file upload with visual feedback
- **React Icons**: Comprehensive icon library for UI elements
- **Axios**: HTTP client for API communication

### **Frontend Architecture & Features**
- **ChatGPT-style Interface**: Professional chat layout that transitions from centered input to full conversation
- **Smart Typing Animation**: New messages type character-by-character, existing messages load instantly
- **Image Upload Flow**: Files immediately move from input to chat when sent, no duplicate display
- **Professional Markdown**: Bold headers, proper lists, clean formatting without distracting colors
- **Session Management**: Conversation history persisted in localStorage across browser refreshes
- **Responsive Design**: Optimized for both desktop and mobile viewing

### **Backend Stack**
- **FastAPI**: REST API framework
- **LangGraph**: Agent orchestration and workflow
- **LangChain**: LLM integration and processing
- **ChromaDB**: Vector database for RAG
- **Groq**: LLM inference
- **Tavily**: Web search API

### **Key Dependencies**
```python
# Core Framework
fastapi>=0.104.1
uvicorn[standard]>=0.24.0

# Agent Orchestration
langgraph>=0.0.40
langchain>=0.1.0
langchain-core>=0.1.0

# AI Models & APIs
langchain-groq>=0.0.1
langchain-tavily>=0.0.1
groq>=0.4.1

# Vector Database
chromadb>=0.4.15
sentence-transformers>=2.2.2

# Document Processing
PyPDF2>=3.0.1
transformers>=4.35.0
```

### **Frontend Dependencies (package.json)**
```json
{
  "dependencies": {
    "react": "^19.2.0",
    "react-dom": "^19.2.0",
    "styled-components": "^6.1.19",
    "react-markdown": "^10.1.0",
    "react-dropzone": "^14.3.8",
    "react-icons": "^5.5.0",
    "axios": "^1.13.2",
    "remark-gfm": "^4.0.1",
    "rehype-raw": "^7.0.0"
  }
}
```

### **Configuration Requirements**

Create `.env` file in `backend/` directory:
```env
GROQ_API_KEY=your_groq_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here
LLM_MODEL_NAME=llama-3.3-70b-versatile
```

---

## ğŸš€ Setup & Running

### **Prerequisites**
- **Python 3.8+** with pip
- **Node.js 16+** with npm 
- **API Keys**: Groq API and Tavily API (see configuration below)

### **1. Clone Repository**
```bash
git clone <your-repository-url>
cd Medical-Assistant
```

### **2. Backend Setup**

#### **Install Python Dependencies**
```bash
# Create virtual environment
python -m venv .venv

# Activate virtual environment
# Windows:
.venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

# Install all required packages
pip install -r requirements.txt
```

#### **Configure Environment Variables**
```bash
# Navigate to backend directory
cd backend

# Create .env file with your API keys
# Copy the template and add your keys:
```

**Create `backend/.env` file:**
```env
GROQ_API_KEY=your_groq_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here
LLM_MODEL_NAME=llama-3.3-70b-versatile
```

**Get API Keys:**
- **Groq API**: Sign up at [https://groq.com](https://groq.com)
- **Tavily API**: Sign up at [https://tavily.com](https://tavily.com)

#### **Setup Medical Document Database (Optional)**
```bash
# Add medical PDFs to the documents folder
cd agents/rag_agent

# Create directory and add your PDF files
mkdir medical_pdfs
# Copy your medical PDF files to this directory

# Build the vector database
python build_rag_vectorstore.py
```

### **3. Frontend Setup**

#### **Install Node.js Dependencies**
```bash
# Navigate to frontend directory
cd frontend

# Install all React packages
npm install

# All required packages are already in package.json:
# - React 19.2, Styled Components, React Markdown, etc.
```

### **4. Start the Application**

#### **Step 1: Start Backend Server**
```bash
# In one terminal window, navigate to backend
cd backend

# Start FastAPI server
uvicorn main:app --reload --host 127.0.0.1 --port 8000
```
**Backend will be available at:** `http://127.0.0.1:8000`

#### **Step 2: Start Frontend Development Server**
```bash
# In another terminal window, navigate to frontend
cd frontend

# Start React development server
npm start
```
**Frontend will be available at:** `http://localhost:3000`

#### **Step 3: Access the Application**
1. **Open your browser** and go to `http://localhost:3000`
2. **Start chatting** with the AI medical assistant
3. **Upload medical images** using drag-and-drop
4. **View API documentation** at `http://127.0.0.1:8000/docs`

### **5. Verify Setup**

#### **âœ… Backend Health Check**
- Visit `http://127.0.0.1:8000/docs` - should show FastAPI documentation
- Check terminal for any error messages
- Ensure `.env` file contains valid API keys

#### **âœ… Frontend Health Check**
- Visit `http://localhost:3000` - should show the medical assistant interface
- Check browser console for any JavaScript errors
- Test typing a message and uploading an image

#### **âœ… Full Integration Test**
1. **Send a text message**: "What are the symptoms of diabetes?"
2. **Upload a medical image** with drag-and-drop
3. **Verify responses** appear with proper markdown formatting
4. **Check typing animation** works for new messages
5. **Refresh page** and verify conversation history loads instantly

---

## ğŸ“Š Request Flow Examples

### **Text Query Example**
```
User: "What are the symptoms of diabetes?"
â”œâ”€ Guardrails: âœ… Safe medical query
â”œâ”€ Image Detection: âŒ No image
â”œâ”€ Agent Routing: LLM selects "RAG_AGENT"
â”œâ”€ RAG Agent: 
â”‚  â”œâ”€ Vector search in medical documents
â”‚  â”œâ”€ Retrieve relevant diabetes information
â”‚  â””â”€ Generate contextual response
â””â”€ Response: "Diabetes symptoms include frequent urination, excessive thirst..."
```

### **Image Upload Example**
```
User: Uploads skin lesion image + "What is this?"
â”œâ”€ Guardrails: âœ… Bypass for medical image
â”œâ”€ Image Detection: âœ… Route to IMAGE_ANALYSIS_AGENT
â”œâ”€ Image Agent:
â”‚  â”œâ”€ Save temporary image file
â”‚  â”œâ”€ AI vision analysis
â”‚  â”œâ”€ Medical interpretation
â”‚  â””â”€ Cleanup temporary file
â””â”€ Response: "This appears to be a benign skin condition..."
```

### **Web Search Example**
```
User: "Latest COVID-19 treatment guidelines"
â”œâ”€ Guardrails: âœ… Safe medical query
â”œâ”€ Image Detection: âŒ No image
â”œâ”€ Agent Routing: LLM selects "WEB_SEARCH_PROCESSOR_AGENT"
â”œâ”€ Web Search Agent:
â”‚  â”œâ”€ Tavily API search
â”‚  â”œâ”€ Process search results
â”‚  â””â”€ Summarize latest information
â””â”€ Response: "According to recent guidelines from CDC..."
```

---

## ğŸ›¡ï¸ Safety & Guardrails

### **Content Safety**
- Pre-processing input validation
- Medical appropriateness checking
- Harmful content filtering

### **Data Privacy**
- Session-based memory (no persistent storage)
- Temporary file cleanup for images
- No personal data logging

### **Error Handling**
- Graceful fallbacks between agents
- Comprehensive exception handling
- User-friendly error messages

---

## ğŸ”§ Customization & Extension

### **Adding New Agents**
1. Create agent file in `agents/` directory
2. Add to routing logic in `agent_decision.py`
3. Update frontend agent list

### **Modifying RAG Database**
1. Add PDFs to `agents/rag_agent/medical_pdfs/`
2. Run `build_rag_vectorstore.py`
3. Vector database automatically updates

### **Changing LLM Models**
Update `.env` file:
```env
LLM_MODEL_NAME=your_preferred_model
GROQ_API_KEY=your_api_key
```

---

## ğŸ“ API Documentation

### **Endpoints**

#### **POST /chat**
Text-only medical queries
```json
{
  "message": "What causes headaches?",
  "session_id": "unique_session_id"
}
```

#### **POST /upload**
Image upload with optional text
```json
{
  "file": "medical_image.jpg",
  "message": "What is this skin condition?",
  "session_id": "unique_session_id"
}
```

### **Response Format**
```json
{
  "reply": "AI-generated medical response based on selected agent"
}
```

---

## ğŸ”§ Troubleshooting

### **Common Issues**

#### **Backend Won't Start**
```bash
# Check Python version
python --version  # Should be 3.8+

# Reinstall dependencies
pip install -r requirements.txt

# Check .env file exists with API keys
cd backend && ls -la .env
```

#### **Frontend Won't Load**
```bash
# Check Node.js version
node --version    # Should be 16+
npm --version

# Reinstall dependencies
cd frontend && npm install

# Clear npm cache if needed
npm cache clean --force
```

#### **API Connection Issues**
- **Backend not running**: Ensure `http://127.0.0.1:8000` is accessible
- **CORS errors**: Check browser console, restart backend server
- **API key errors**: Verify `.env` file contains valid Groq and Tavily keys

#### **Image Upload Problems**
- **File size**: Maximum 10MB supported
- **File format**: JPG, PNG, GIF, BMP only
- **Upload flow**: Images should disappear from input immediately when sent

#### **UI/UX Issues**
- **Typing animation**: New messages should animate, refresh should show all instantly
- **Markdown rendering**: Headers should be bold, not show raw ### symbols  
- **Scroll behavior**: New responses should show from top, not auto-scroll to bottom

### **Development Tips**

#### **Frontend Development**
```bash
# Start with hot reload
npm start

# Check for linting errors
npm run lint

# Build for production
npm run build
```

#### **Backend Development**
```bash
# Start with auto-reload
uvicorn main:app --reload

# Check API docs
# Visit: http://127.0.0.1:8000/docs

# Test individual agents
cd agents && python test.py
```

---

## ğŸ¯ Project Highlights

### **Advanced UI Features Implemented**
- âœ… **ChatGPT-style Interface**: Professional chat design with smooth transitions
- âœ… **Smart Typing Animation**: Time-based detection prevents replay on refresh  
- âœ… **Professional Markdown**: Bold headers and clean formatting for medical content
- âœ… **Seamless Image Upload**: Files move cleanly from input to conversation
- âœ… **Session Persistence**: Conversation history maintained across browser sessions

### **Multi-Agent Intelligence**
- âœ… **Intelligent Routing**: Automatically selects best AI agent for each query type
- âœ… **RAG Integration**: Search through medical literature and research papers
- âœ… **Vision Analysis**: AI-powered medical image interpretation
- âœ… **Real-time Research**: Access latest medical information via web search
- âœ… **Content Safety**: Built-in guardrails for appropriate medical discussions

---

This Medical Assistant provides an intelligent, multi-modal approach to medical query processing, ensuring users receive appropriate responses through the most suitable AI agent for their specific needs.